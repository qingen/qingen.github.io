---
layout: post
title: 深入剖析 LSTM 建模和 CTC 训练
category: ai
tag: asr
excerpt: 百度大咖的分享就是透彻
copyright: tip
lock: need
keywords: ctc lstm asr

---

## 0. 写在前面
来到百度后，已有1年半多了，还没有写博客来记录一下。晚上翻了翻以前的资料，发现一位语音大咖前几年的的演讲材料，很多地方不通顺，估计是ASR直接转文字的，也没有校对，所以我人工把这个活给干了，特地分享给大家

![](/assets/images/2020/ai/baidu01.jpg)

> 风雨不动安如山，加班结束后下雨等车的时候拍的

## 1. 语音识别 LSTM 声学模型
语音识别，简单的解释就是将语音转化为文本，可以应用在智能对话，语音控制，录音转写等领域，是目前人工智能比较火的子方向之一

一个语音识别框架，大体有三部分构成，声学模型（发了什么音），语言模型（音对应的可能的字），解码器（如何有效的利用音与字，得到最优的结果），本篇博客先讲讲声学模型，以及 解码部分

先简单介绍一下长短时记忆模型(LSTM,long short term memory)。这个模型的优势就在于，在传统的网络中引入三个门：输入门，输出门和遗忘门，分别代表对信息长期、远期和近期的记忆和控制

![](/assets/images/2020/ai/ai01.jpg)

> LSTM 结构图


相对于我们传统的 CNN和 DNN模型，它的好处是能够记录轨迹的变化。这个模型已经提出来很久了，本身并不是近期的创新，但要把它应用在工业里，比如用在小度音箱上的语音交互，或者车载的语音控制上，是有很多困难和现实问题的

为了把模型应用在产品上，我们提出了一套CNN+7DNN+2LSTM的结构。Google当时提出的是2层LSTM，在我们的验证中，如果是对于状态建模，那么需要比较 Deep 的模型，因为这是比较短的瞬时状态，它的轨迹并不清晰。

那么如果采取这种深层结构，经过两三轮的迭代，数据就可以获得收敛，并有很好的效果。但如果只用2层的LSTM，随着数据量的增加，这个提升会很慢。Google 最后的论文也证实了这一点，深度的模型结构，对于状态建模是比较好的。我们在LSTM的模型上，主要解决了海量数据的训练和效率问题。

LSTM的训练是有困难的，因为很容易发散。为此Google提出的LSTMP，它在传统的LSTM模型之上，引入了一个反馈层。这个反馈层对工业界弥足珍贵，因为这个反馈层会使运算的计算量大幅下降，它可以把反馈的，比如说你这个神经元节点是1024，他反馈的可以采用256，这样整个计算量会大幅压缩。

![](/assets/images/2020/ai/ai02.jpg)

> LSTMP 添加反馈层 结构图

因为LSTM的输出层很大，它有两万多个节点，在状态建模的时候，为了和外部的匹配，LSTM的记忆单元c的维度也会比较高，一般采用的是1024，也可以采用2048。当采用1024的时候，其实整个网络已经非常复杂了。

但是引入反馈层后，可以把参数大幅的压低，从而可以让你鲁棒稳定的去训练这个网络。但有人反映，带有反馈层之后训练会不稳定。我的感觉是这种反馈即使有不稳定，大家要去钻研，因为它是必不可少的。工业产品中如果不带这个反馈，计算量是难以承受的。

## 2. BPTT
BPTT算法，BPTT算法是最基本的训练神经网络的算法，就是误差反向传播。对于R模型或者LSTM模型它是有轨迹的，因此它是根据轨迹的误差反向传播。它有两种方法。 

第一种方法是逐帧递推的，一帧推下一帧，再下一帧误差规避以后再向前传。 

第二种是所有的误差同步向前传，传固定的步数。 

![](/assets/images/2020/ai/ai03.jpg)

> BPTT示意图

这两种算法其实在BPTT的理论都是存在的。后面这种实际上就是把误差截断，不让误差从头传到尾。第一种就是直接从头传到尾。**实际落地的一般是后者**

## 3. 百度多层LSTM声学模型结构

![](/assets/images/2020/ai/ai04.jpg)

> 多层LSTM声学模型

这是我们多层的LSTM的结构，前面是CNN层，中间是DNN全连接层，最后是两层LSTM。

其中LSTM的 C 采用了1024，这个维数的大小，在目前我们的工业产品是可以用的。

这里解释下该网络结构对提升系统性能的根本原因： 

第一，多层结构对神经网络而言总是有价值的，因为多层意味着输入的扰动在输出总数会衰减。这个可以参考微软的于老师的一篇论文。

第二个状态建模，研究发现状态的轨迹并不是很清晰，很短、很sharp的一个建模单元。这个时候如果完全采用LSTM去建模的话，造成的结果就是LSTM是轨迹比较强，但是它对瞬态的模拟能力就不够了，因此瞬态跟轨迹结合的这样一个模型结构，在我们现实产品中发现是稳定的，而且总是有好的效果。 

那我们和双层的LSTM做对比，谷歌当年刚开始提出双层的LSTM胜过CNN，有这样一篇论文，大家可以去找，我们做了实验，实际上我们达到的是negative的结果。在2000小时中，跟谷歌的实验一样配置，但是双层LSTM的效果没有胜过传统的CNN技术。 

但如果把数据量增加到一万小时的时候，这种十层的CNN会胜过双层的LSTM，节点是1024，大家可以做实验看看。因为LSTM的特点是节点多，记忆能力就强，但是节点如果少的话，能力就有限。

1024是工业能上线的技术指标，我们把LSTM变成这种结构的时候，就能够很好的胜出了DNN和CNN。

最后谷歌的论文也证明了这一点，所以我相信这个应该是目前大家都没有异议的东西。

## 4. 谷歌分子句训练 VS 百度整句训练

再讲讲训练方法，谷歌有一个很著名的训练策略，我觉得是这个策略把LSTM带入语音工业界了，因为LSTM很慢，逐帧的训练基本上在现实中是不可能的。那么谷歌的策略是：首先把句子随便的排在一起，每一次取一个SubseqSize（子句），这个子句会有一个 Batchsize，64个句子放在一起，子句是20。

![](/assets/images/2020/ai/ai05.jpg)
> 谷歌分子句训练

我们知道传统的LSTM是轨迹训练，而我们的CNN是逐帧训练，上述训练策略把LSTM向逐帧训练靠拢。这样核心收益就是，CPU在计算的时候是可以高速计算和高速并行的。

由于这个技术的引入，把LSTM的训练速度大大提升，从而工业界可以使用LSTM做语音识别。

那我们的训练结构基本上就是一种多GPU的方案，我们把这个句子划分成多个机器，每一个机器都采用一种分子句训练，得到的结果，然后用单机同步，或者异步SGD。

![](/assets/images/2020/ai/ai06.jpg)
> 百度整句训练方法

我们最新研究的**整句训练**的方法，整句训练的难度会非常大，因为单帧递推的话，一般都是两三个句子，误差都会从头推到尾，从尾推到头。

这个训练量会非常的大。而这个是我们认为后续提升的关键，谷歌的分子句训练在我们的实验中无法做CTC的Training。

那整个的训练要全部切到整句训练上，这个跟传统的训练方法就会有一个很大的差异，这个差异是造成CTC训练在语音识别中使用的核心瓶颈。

## 5. 并行训练平台

在我们的并行训练平台上，之前的CNN，DNN或LSTM网络，都可以单机去训练。但是做这种整句的训练情况，单机已经很难完成任务了，一般需要使用多机，把模型去平均，让模型传递的时候归并更加容易。 

![](/assets/images/2020/ai/ai07.jpg)
> 并行训练平台

这是一种新型拓扑结构，用于异步SGD，用多机去做，我们大概是四到八个机器，一个机器有四个GPU卡，因为单机的速度实在慢到无法忍受。我们的数据训练量是谷歌的四到五倍，模型体积是谷歌的五到二十倍。这个巨大的差异能体现我们工作的一个重要的核心价值，因为当LSTM做CTC训练的时候，整句的训练会形成一个巨大的技术瓶颈。谷歌的模型很小，双向的模型只有300个节点，单向的模型只有500个节点。 

我们双向的模型用到了1560的节点，我们单向的模型用到了2048个节点，这样的规模是适合工业界去大量产品使用的。工业节点使用的时候一定要考虑未来的训练语料库是十万小时，如果你做了一个算法，只能做一万小时，或者是五千小时的训练，那这个算法长期去看是没有工业生存价值的，**这是我们工业界思考的一个根本和立场**。

所以，这个工作难度的核心就在于训练速度的提升，这个速度的提升是超乎我们常人想象的。因为当年CNN和DNN技术，我觉得于老师和邓老师把这个DNN做起来一个核心的原因是GPU带来的计算量的提升，因为GPU本质上改变了CPU，提升大量的并行度，所以LSTM算法得以流行。

 而如果CTC如果想训练的话，一定要有整句训练，而整句训练的训练速度是会造成所有人的技术难题的。而这种难题在工业界中实际上尤为突出，**因为我们的训练量太大**。在学术界上，我们探讨一些理论结果，不一定是要大数据。但是我们工业界，一般都是在巨大数据量的验证下得出的，并且具有更强的理论意义。

## 6. CTC的引入

![](/assets/images/2020/ai/ai08.jpg)
> 模式分类

那么我先讲下CTC，在分享之前先介绍一下静态分类。静态分类就是橘子，菠萝，还有桃子，其实你做这种分类很简单，是一个分类器。CNN和DNN就是简单的静态分类器，当我们去训练LSTM的时候，大家可以回忆一下。采用谷歌的分子句训练，实际上大家也是模拟单个的状态，在每一个子句中间我们可能有误差和递推。但是实际上它是一个静态建模，建模的目的就是模拟输出状态。 

而序列分类就不一样，他是直接把一个序列映射到另一个序列，从头到尾的去做训练。而这种序列训练的建模理论和基础和我们传统的语音识别差异很大，它本质上并不是静态分类器，它是动态分类器。 

语音识别本质上是训练DNN模型、CNN模型，甚至训练LSTM，多多少少都有静态分类的影子。而CTC训练是真正的序列训练，优化整个序列的损失，而不是优化单点的损失，所以要将CTC应用于语音识别上，实现动态分类。 

![](/assets/images/2020/ai/ai09.jpg)
> CTC和HMM的对比

那在展开训练之前，我想再对比一下CTC训练跟传统语音训练HMM训练的不同。

那HMM训练是有这样一个拓扑结构，这个输出分布换成GMM或DNN，这样的分布，大家建模的时候实际上拓扑是固定了，大家只是训练这部分。这部分东西，我们先得到一个模型初值，切分出边界，在固定边界的学习下，把GMM或DNN模型调到最优，然后再切分得到新的边界，再用新的边界更新GMM或DNN的参数，这样反复多次即可。这是我们传统的一个学习分量方法。 

虽然我们实现了动态训练分类，但是我们的训练和本质上是静态分类器，我们没有做动态分类器的动态直接训练。但是CTC训练不同，CTC是直接的动态序列学习，它是要优化整个序列的可能性，什么叫整个序列的可能性？

![](/assets/images/2020/ai/ai10.jpg)
> CTC 自然语音的识别率提升

比如说话ABC是一个序列，那么插入空白(blank)或自身重复，这样形成的新序列（可能的序列），如 AABBlank CC，AblankBBblankC等对应的全是ABC。任何一种序列可能的展开，都是这个序列的实例。它并没有固定的边界，那引入了一个重要的空白模型。空白模型是无意义的，表示没有任何的物理意义，这个模型就是硬引入来的。blank空白是可以跨越的，也可以经过

黑点表示实际的ABC观测，是不可跨越的。可以多帧驻留，但是不可以跨越。空白也可以多帧驻留，这是CTC理论模型，实际上非常可贵，而且CTC模型是否训练成功，就依赖于这个拓扑是不是和语音一致。  

那这个模型好不好，能不能在精度上超越我们现实的语音世界？我再解释一下CTC的实际训练情况，刚开始的路径首先是空白，按照刚才的拓扑结构，空白可以经过，也可以跳跃。空白也可以多帧注流，可以跳向有意义的实际建模单元，建模单元也可以跳过空白到下一个。 

整个的空间展开是固定序列约束的解码。什么叫固定序列，我知道我的目标序列是ABCDE，我把ABCDE整个空间在这个模型的拓扑结构上全部去展开。

这里我觉得只要大家是传统做语音识别的，全部是这样的思路。所以当机器学习的人最初提出CTC的时候，很少有语音识别的人去追求，甚至到现在很多人，包括我在9月份的interspeech开会，谷歌的学者讲CTC的时候，底下很多人尤其是传统语音识别的人是不信的。因为这东西在传统的语音识别框架中完全存在，我们也完全能做这个事情，这个东西能有提升吗？其实大家都是不相信的。


包括谷歌的实验结果，谷歌实验结果有一些前后矛盾的地方，它得到的提升不足10%。而状态判断的准确率很低，就是一个双重的S型状态。谷歌并没有给出原因，为什么CTC能提升。 

那然后讲一讲CTC的函数优化，CTC是优化整个无空间序列，这跟我们的图空间是一样的。但是有一点不一样的，CTC并不是全局Normalize，CTC是在逐帧Normalize打分。

CTC不可能和GMM融合，而必须用轨迹建模，这就要用RNN、LSTM进行轨迹建模。CTC训练必须采用整句训练，综合考虑全局的上下文信息，力求全局对比。然后我们讲空白，CTC模型有两个伟大之处。

![](/assets/images/2020/ai/ai11.jpg)
> CTC 自然语音识别率的提升

第一个伟大之处是全局Global。 

第二个是空白，CTC有特殊的空白模型，我们语音识别有SP，我们有长境义和短境义，我们短境义也有，那它那个空白跟我们的空白有什么差别。

那我可以讲一下，引入blank的类别，它的作用主要是较好的解决**两个建模单元之间的混淆性**。比如说这是两个建模单元的边界，边界的地方我们是切分切出一个边界，这个边界似是而非，说属于前面也行，说属于后面也行，讲不清楚。这种情况下，CTC模型的空白可以吸收这个边界，对于我们的疑问是，我们的SP模型是不是也能干这个事情。 

对应的第二个，将传统的轨迹学习转为差异化学习。CTC的模型结果，一定是当前的建模单元只有一个脉冲信号。我并不是在描述轨迹变化过程，我是在描述差异性。哪一帧信号最能代替这个因素，这是CTC训练的理念实质。

还有CTC训练天然解决了语音和非语音的区别，他们的区分性不是那么重要了，因为CTC已经搞定了。当你在区分训练的时候，更重要的是区分语音之间的混淆性。

这一点实际上是通过一帧信号来代替一个观测量，你说R这个因素可能维持时间很长，但是代表的特征只有一帧信号。然后讲一下CTC实际的前后项算法的特性，这个热力图代表的是误差分布函数，这是从前到后的误差分布，这是从后到前的误差分布，这是两个合到一起的误差分布。

## 7. CTC的前后向以及解码

![](/assets/images/2020/ai/ai12.jpg)
> CTC 前后向算法以及解码

这个热力图反映了什么，CTC这个误差从前向后的时候误差非常集中，说明从前向后对这个声音的确定性很高。但是从后向前的时候，声音迅速分散，代表声音的不确定性很高。

这说明在语音识别中，从左向右对语音识别的结果贡献更大，从右向左有价值，但并非很重要。这意味着，我们可能做单向的LSTM模型，不需要右边的文本，也许可以精确建模。

而只有单向的LSTM模型才是工业产品可以接受的，因为它没有延迟，可以在线去解码。那么这个理论的分析结果，是在做之前实际上我们就想探寻的。如果后向Dominate了这个Process，那CTC的训练必须依赖右边的信息，否则的话整个语音识别是没有办法，整个的CTC训练是没有办法很好的收敛的。

但是很有幸，左边Dominate，右边有价值。CTC的解码过程，实际上CTC的空白占了绝对的优势，我给大家只是找到了一个简单的例子。比如说我们建模“简单可依赖”，那我们就简单每一个字去建模，blank可以无限延展，最后的解码路径就是这样的一个路径。每一个字只有一帧，无论你是什么样的建模单元只有一帧。那这样的解码结果，在解码的时候会有很多优势，我们会有一个解码的算法加速。

然后CTC训练了尖峰生成，大家用机器学习直接做CTC训练，就是从一个裸的模型就硬做，也可以做到。我见过很好的结果。在做的过程中，我们用一个概念叫拉尖峰，这个尖峰是一点点拉出来的，刚开始这个锯子什么也没有，“简单可依赖”的几个字，可能拉出来一个简单可可出来了，然后逐渐的拉紧，就把简单可依赖尖峰生成。那么对应的右边是误差的降低，刚开始的误差很大，逐渐误差会降低，这就是CTC训练的优化过程。

![](/assets/images/2020/ai/ai13.jpg)
> CTC 算法

那么CTC有两个问题，第一，CTC能够提高人类对于语音的辨识能力吗，这个实际上是一种能力，这种算法是不是超越了现在所有的。第二个CTC能提供能提供工业产品的识别率吗？这个是有差异的。

比如说第一种方法我可以采用双向的建模，我可以采用多best的解码，反正我就无休止的做，我拿到最好的结果，我跟人去PK。第二个结果是指工业产品有设定的要求，尤其是在线解码的很多的需求，不能让用户无偿的等待，以及计算机计算资源的消耗，必须满足产品要求，那实际上这是两个问题。

## 8. 与HMM-DNN的比较

![](/assets/images/2020/ai/ai14.jpg)
> HMM-DNN和CTC的差异

那么我主要想对比一下HMM，DNN和CTC的差异。第一是模型结构差异，CTC引入了blank，我们实际上是有SP的，但是我姑且把它命名为差异。第二个CTC训练无须固定边界，对CTC而言是不需要的，裸的模型随便给我一个序列我可以做，自动的end to end 优化模型参数，这是他对应的两个，这是传统我们的CE训练，我们必须知道这个label，根据label算出误差去优化网络，那上面这个模型训练实际上就是CTC的模型。

那我们做CTC整个training的过程，我不是去拉尖峰，我是按照压尖峰的模式，我的尖峰都是往下压的。我的训练过程实际上是这样一个过程，首先出来两个空白，空白长大一点，空白又长大一点，空白再长大一点，最后留下来了一个尖峰，这是我的训练过程。我所有的训练都是采用这种训练模式，推荐给大家，大家可以选择，希望大家可以提出比我更好的训练方法。 

![](/assets/images/2020/ai/ai15.jpg)
> CTC建模的区分度训练

CTC训练的区分度是非常关键的，区分度我用美国微软研究院的，当年是我的老板Jeff的话说这是艺术。区分度训练不是技术，很少有人能做的很好。这个东西全部是要通过各种细节去调节，全部运用参数去做。但它是语音识别领域对人工智能的重要贡献，这一点我永远引以为傲。在所有的机器学习理论中没有区分度训练，我认为区分度训练才是真正的end to end的学习。他直接得到解码结果，根据解码错误反馈来修正误差。

CTC的区分度跟传统的区分度没有差别，这里有两个重要的，一个是深度学习网络内部的梯度，一个是解码的区分度信息，这两个实际上是在一起的。然后我们可以在做CTC模型的时候，我可以对CTC模型维特比得到固定边界，这一点我们就是我们是这样做，大家也可以不这样做。

这个实际上就已经进入了传统语音识别的领域了，我有一个模型，我做一次切分，哪一个最大，哪一个定一些边界。得到固定边界之后，我们就可以进行区分度，这个过程跟传统的区分度一模一样，但是空白对CTC很关键，需要去做。

然后异步SGD的优化，我这个训练是采用异步SGD去做，我是属于一边解码一边update 模型，我两个是一同去做的。区分度训练CTC模型的收益和我的固定边界的模型是相当的，所以这一点是非常可贵的，这是我们区分度的结果，我们都有所有的实验。 

![](/assets/images/2020/ai/ai16.jpg)
> CTC的解码

然后我要讲的是CTC的解码，那CTC技术的解码，实际上跟传统的解码是有一定差异的，第一在图状态空间构建的时候，

每一个原来的你的一个建模单元，我们都是采用单状态。原来的一个因素必须是三状态，这是传统的状态建模，CTC是单状态的。

同时要增加一个可跳转的空白。解码的那个图空间构件基本元素就是这样的拓扑，CTC的解码很快，从两倍实施，把DNN打出来的结果固定，只是去算解码的时间。两倍的时速很慢，我把时间放的非常快，缩短到0.15倍实施，识别率没有任何降低。而缩短到0.05倍实施，识别率只降到0.2。

这说明什么？这说明语音识别的解码器的耗费全部转化为DNN的计算了。而语音识别解码器，一个机器，一个现有的PC器可以handle更多的解码，因为它的解码速度很快，lost很低，这使语音识别未来的发展具有很大的工业的价值。因为现在的语音识别cost很高，你支持一核，一线的服务这个是很花机器的，如果50%用语音搜索这个事搞不定的。但是如果这样去做，我们把语音识别的解码速度大幅的提升，如果计算量全是DNN的话，那是跟容易办的。DNN我相信一定会有大量的专业硬件去做DNN的计算，据我了解很多公司都在做这样的研究，这个东西是一定可以解决的。所以这样的话，语音识别未来是可能的，就是大面积的语音识别的采用是可能的。

然后我们可以把我们的解码的算法告诉给大家，让其他的东西你们找不到，其实很简单，在解码有空白段的时间，这个search的beam值是动态的自适应调节的，如果你确定当天是空白，这个beam可以大幅度的去削减，这样解码的速度就会很快。

## 9. 我们做的实验

![](/assets/images/2020/ai/ai17.jpg)
> 基线系统，区分度的基于状态的LSTM建模

我们的基线系统，因为只有你知道我们做了什么基线系统，你们才知道我们这个工作是不是有价值。那么谷歌当时在inter speech的会议上，被微软当时一个学者问他的结果，最后谷歌的结果有点不一致，因为它的基线很低，它的基线就是一个两层的LSTM。

而我们的基线，状态是两万的状态序列，参数是这样的参数结构，DNN的节点都是2000个。LSTM的系数是1024，反馈是512。

这个模型非常的大，这是我们的商业系统，我们就在这样一个商业系统。然后训练数据量我们用了将近一万小时，并非觉得大数据就很重要，只是这个技术的核心难点就在于训练速度，如果我们不能证明我们的算法可以用于十万小时，那这个技术做的是没有意义的。

所以相比谷歌，他们是用2000小时去做，而且模型小了很多，我们的模型很大。然后我们用的优化准则实际上是这个系统，是单机同步训练。训练方法是传统的谷歌分子句。那谷歌分子句的训练方法实际上是被证明非常有效的，那么原模型大概就是几十个G左右，然后我们做这个试验的时候，要求12和实现的解码速度达到0.5，就totally的解码速度，因为代表一个工业的基础要求，因为我们做一个事情总要知道它的解码速度是多少、LOST是多少，这个是我们解码速度问题。我们把我们的基础系统完全地交给大家），大家知道我们这个工作，跟什么做比较，这是我们的试验，我们几乎做了我们能做的所有的实验。

![](/assets/images/2020/ai/ai18.jpg)
> 我们的实验总结

 首先状态实验，状态实验首先基本模型是这个模型，我们不知道拓扑是不是有价值，于是我们就引入拓扑。我们也不知道是切分有价值还是交替，是切分的作用还是交替训练的作用。

然后双向的时候，也做了类似的工作，那么对音节或者整个汉字建模我们也做了很多的模型，那我们这个模型的情况呢，首先整个音节建模CNN我们做，然后音节用的是5层的LSTM建模，1560节点，这个模型很大，双向的。整个就是用，这样做的目的我们就是想看一看，在音节模型上，这个算法的形成到底怎么弄。

其实，对于CTC而言，从理论上它不存在任何建模的困难，这是bulitable 的技术，在我的研究中我发现，就是任意的虚点，无论你的建模单元有没有意义，无论它有没有区分性，只要你给我足够的数据、足够大的模型，我一定可以训练出很好的结果。所以在音节实验中，我的模型取的偏大，那如果更大，又会不一样

而对声韵母建模，我们标准采用的是我们产品中可以采用的策略。首先，这样文本的声韵母12000个，然后CNN+DNN是9层2048节点，这是标准的CNN模型的配制。然后是CNN加5层LSTM 1024节点，还有2048节点，还有1024的结果。

那么，这个结果是有区分度结果，因为这个结果和这个结果可以比，因为它的模型参数是一样的，我在比较，如果我再这个模型参数条件下，2048节点的5层的话，上线是很困难的。

我在我上线的目前极限的情况下，我去比音节建模跟声韵母的建模的文本的差异，我力求发现，CTC的本质是什么。

## 10. 我们得出的实验结论

![](/assets/images/2020/ai/ai19.jpg)
> 实验主要结论

第一个结论就是，基于整句训练的LSTM建模，如果我LSTM建模，可以让汉语采用状态半音节和音节，效果都不会差。所以，这一点我觉得这个实验实际上是跟大家以前的理论不一样的，我们必须做状态，不做状态不能做实验，其实不是。我任何一个建模单元，我如果采用LSTM去训练，那么我都可以达到一个不错的结果，取决于模型多大、训练数据多少。这样语音识别传统使用了几十年状态建模实际上不用采用了。

然后呢，固定边界学习的LSTM和CTC的结合，那这就是CTC的价值和作用。第一个，在状态建模系统中，CTC训练没有成功，因为状态很短，CTC很难在一个很短的序列中找到blank，给你一个好的表现，通常的结果会有两三个absolute job，就是你的点很差。

然后如果音节单元自身具有混淆性，比如说音节或者是现在的end to end 的学习，当然没有任何意义，你给我一个序列，我找到标签你去做，那都是可以的。那么这样去做，CTC的价值是，牺牲了建模单元内部的混淆性，比如音节ā和à差别很小，但是我依然可以把这两个模型区分开。让机器学习去做，CTC是能够做到的，从而提升了LSTM的建模能力。

那么CTC是个训练准则，训练的模型是LSTM模型，那么这两个结论实际上已经说明，用机器学习的知识，不要任何语音识别的先料，我硬做，是可以做出一个系统。

这个系统怎么样，我们结构也是一样的，跟现在的系统情况非常接近。那如果是这样的结论，那几乎我们做语音识别的人就跟教师一样，人家跟我们拿的结果是一样的，那我们的价值在什么地方？

我觉得是传统语音识别的所有工具，我们把CTC训练引入到语音识别的框架中，采用语音识别的很多技术去优化。我们发现，比如说用双向的LSTM建模，不需要用CTC效果一样好。那这个结论是很重要的结果，大家要想做CTC的算法，先做出这个结论，如果你的双向的LSTM避逃不了你现在的线上系统，那你的LSTM有问题。

那做完这个结果之后，那我们来做一个实验，就是对我们有指导意义了，我们对于单向的LSTM采用1024建模，必须采用CTC，我们取得了性能超越现代系统的一个进步。

那就是说CTC对语音识别的价值在我们的实验中，在双向系统中没有明显的价值，说明CTC对人类的认知能力的提升，至少我的实验中没有证明或者说是略有提升，也是非常小的。

但是CTC的单向LSTM中，价值无可替代，有非常重要提升，那这个提升的价值主要是CTC引入了空白，它有空白，空白在这个训练中可以形成target delay，因为我不知道右边的信息，比如说a这个音，后面是什么我不知道，我就让你延迟几桢再决策。

所以它自动形成了它这个target delay以后，相当于把右边的信息补全，所以CTC的性能在语音识别中，对单向的才会大幅度提升。

而对于双向的模型，我无限的数据、无限的模型、好的训练算法，我一样可以学习到一个东西。所以，CTC不是灵丹妙药，这是我的理论的结果。

我相信，会有大家更多的人去分析、去追求，甚至于否定我的理论，我很欢迎，但是至少今天，我愿意努力地给大家share一下，我们的理论发现，那从而帮助大家更好地去做CTC的学习和训练。

然后，大数据的大模型的结论呢就是说，数据将近万小时的时候，我们采用的是1024和2048，因为1024是可以上线的，所以没必要采用更小的，那更小的性能我们可以再去做追求。

## 11. 对学术以及工业发展的影响

![](/assets/images/2020/ai/ai20.jpg)
> 主要影响 

第一点，大数据下极致训练速度的追求是必须的。如果没有极致化的训练速度，你们很难得到好项目。这个相比于传统的技术，如果你要想提升，你需要采用上下文相关的声韵母建模，你还要采用固定边界的训练，再用CTC，再用区分度，最终可以降低产品误识率15%以上，我们得到的收益远远大于谷歌。谷歌当时的收益不足10%，它的论文中，我们的收益很大。而且是跟一个产品性能去比。那么本工作和未来语音识别的贡献呢，就是未来的语音识别服务将不再昂贵，那么我觉得，这是刚才已经解释的技术。

第二呢，语音识别的建模单元从禁锢了几十年的状态建模中会被解放出来，那么如果不用状态建模，你可以采用更复杂的、任意的模型。CTC建模理论上可以让你学到一个很好的结果，那么你可以尝试，什么样的建模单元能够减小语音识别率。

那么，第三点，我觉得也有启示性价值，近万小时的训练条件下产生了过拟合，过拟合是我在CNN和DNN训练中没有看到的。但是对CTC，对目前的学习，我发现了过凝和，那这是很好的效益，说明继续加数据对算法还是会用提升的。

第四点，语音识别的深度学习技术呢，我觉得就向极致计算去发展，那整个工作最核心的价值是计算能力，当年的DNN能够成功是挖掘了GPU，我们现在要挖掘的是把GPU的能力挖掘到极致，会有多个GPU去并行运算，更大规模的并行运算实际上是能推生这个的发展。

![](/assets/images/2020/ai/ai21.jpg)

> 与前人工作的一些差别