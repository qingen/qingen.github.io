---
layout: post
title: 机器听声音也能分辨男女？
category: ai
tag: vpr
excerpt: 有时机器真的不比人差
mathjax: true
keywords: 性别识别 gender recognition
---

## 0. 写在前面

搞了多年的性别识别的算法在智能硬件上的应用了，可是一篇博文都没有记载，这几天把以前的资料整理了一下，放在这里，分享给大家，欢迎指正批评

本想找一个曾经的天猫精灵智能音箱的照片，找不到了，就用下面的代替了，哈哈，就纯属回忆了。。。

![图片](/assets/images/2020/ai/ali03.jpg)
>2015年11月22日，阿里总部，杭州西溪园区，双11刚过没多久，这一次的主题可以看出是 Rock the World


## 1. 背景

性别识别在信息时代有着广阔的应用前景，其可在身份识别中充当“前滤镜”的功能，即可利用检测出的性别信息减少在身份识别的搜索范围，从而提高身份识别的速度和精度，性别识别也能在安保系统中起到较大的作用。现在的一些设备无法识别用户性别信息，如果可以识别用户性别的话,对于提高机器学习效率及其智能化程度具有一定的意义。

因此，可以将性别识别加入到声纹平台中去，去赋能更多的业务方，提供强有力的身份验证的辅助支持。

基音频率是性别识别最重要的判别依据。它反映了说话人发浊音时的声带振动频率。一般而言,男声的基音频率分布范围为0~200Hz,女声的基音频率分布范围为200~500Hz。因此,准确而可靠地估计基音周期对于说话人性别识别非常重要。判断说话人的性别可以采用类似说话人识别的方法,常用的性别识别方法有VQ算法、HMM算法、支持向量机方法，GMM建模，以及最近几年很火的DNN，LSTM，CNN等各类神经网络；本文选用高斯混合模型(Gauss Mixture Mode,GMM)，以及DNN-Embedding xvector 进行性别识别，并对比两者的效果

## 2. UBM-GMM 性别识别系统

### 系统框架

性别识别是一个典型的模式识别的问题，因此也具有模式识别中最典型特点，当前的性别识别的研究重点可粗略地分为：

- 特征提取：寻求一种能很好区分不同性别的特征，并对噪声和信道有很好的鲁棒性。
- 模型选择：寻求一种能够准确利用所提取的特征来描述性别的语音分布。
- 计分和判决：从模型得到分值作出可靠的判决。

性别识别的 GMM-UBM 系统框架如下图，基于上面的讨论，可以分为三个模块：特征提取模块，作用在于从语音中间提取出声学性能很好的特性参数，能够对噪声和信道具有很好的鲁棒性；模型训练模块，用于训练通用背景模型(Universal Background Model UBM)以及自适应各个性别的声学模型；测试模块，主要处理得分，包括得分归一化和后端分类。

![图片](/assets/images/2020/ai/gmm01.jpg)

#### 特征提取

我们首先对数据提取MFCC参数，采用[kaldi](http://kaldi-asr.org/)工具提取特征参数，得到 7 阶MFCC系数(C0－C6）。 MFCC按 7-1-3-7（N-d-P-k）扩展为 49 维SDC。我们把 7 阶MFCC系数和 49 为SDC拼起来得到 56 维特征。在提取 56 维特征中，我们采用VAD算法去除静音帧，特征参数还通过CMS，高斯化和RASTA进行倒谱域滤波去除信道卷积噪声。具体流程如下：

![图片](/assets/images/2020/ai/feature01.jpg)


##### MFCC

梅尔频率倒谱系数（Mel-Frequency Cepstral Coefficient ,MFCC）是一种听觉感知频域倒谱参数，该参数从人耳对声音频率高低的非线性心理感觉角度反映了语音短时幅度谱的特征，因此无论在语音识别还是性别识别中都得到了极为广泛的应用。

根据 Steves 和 Volkman 的研究，人类听觉系统所感知到的声音的频率(Mel)与该声音的物理频率(Hz)的对应关系并不是完全线性的，而是在一定范围内呈对数关系。若定义 1000Hz 处的频率对应于 1000Mel，则这样一种对应关系在 1000Hz以下近似为线性，而在 1000Hz 以上则近似为对数关系。 Mel 频率与实际频率的关系可以用下式近似表示：

$$
Mel(f) =2595log(1+f/700)
$$

梅尔刻度三角滤波器组：

![图片](/assets/images/2020/ai/feature02.jpg)

MFCC 提取过程：

![图片](/assets/images/2020/ai/feature03.jpg)

##### RASTA滤波

RASTA是Rel Ative Spec TrAl这个词组的简称，是Hynek Hermansky等人根据人类语音听觉感知对于激励源缓变不敏感的这种特性，提出的一种对于语音参数的时间轨迹进行滤波，以便从语音的参数表示中减小非语音部分的频谱部分的方法。最初把这个算法用在PLP特征参数上，后来发现用在其他的倒谱参数上也可以使性能提高。

RASTA 处理通常在对数谱或对数功率谱域进行，也可以在经非线性压缩后的倒谱域或功率谱域进行。它使用的主要部分是一个带通滤波器，此带通滤波器是一个 ARMA 滤波器，可以表示为如下的形式：

$$
H(z) =0.1*\frac{2+z^{-1}-z^{-3}-2z^{-4}}{z^{-4}*(1-0.98z^{-1})}
$$

RASTA 滤波处理是一个低端截止频率为 0.26Hz，从 12.8Hz 开始每弧度衰减 6dB，在 28.9 和 50Hz 附近有 0 点出现的带通滤波器。通过 RASTA 处理后，频谱中的常量或者变化缓慢的部分被抑制，动态成分被增强。

实际上 RASTA 滤波器应该是一种经验公式，纯粹是从实际应用中总结推广出来的，上式的系数也可以任意变化，上述公式是一个带通的滤波器，实际中对于频谱的滤除不一定需要带通，但是在实际应用中上式一般都能取得良好的效果。

##### 移位差分倒谱特征

SDC 特征（Shifted Delta Cepstra）也称为移位差分倒谱特征，是由多个连续语音帧的一阶差分谱扩展连接而成。对于性别识别来说，特征提取一般是通过计算第 t 帧语音信号的倒谱和差分倒谱来实现的。然而，近来相关研究表明，通过使用由若干块跨多帧语音的差分倒谱构成的转移差分倒谱特征向量，从而使一帧特征能够包含其后多帧语音的长时声学信息，能取得更好的性别辨识效果。

下图说明了移位差分倒谱特征向量的计算。

移位差分倒谱特征向量主要有四个参数： N-d-P-k

- N 定义了每帧语音计算用到的倒谱个数，
- d 定义了计算差分的时移，
- P 定义了差分倒谱块的转移量，
- k 定义了一个 SDC 特征向量包含差分倒谱块的个数.

显然，每一个 SDC 特征向量包含 k×N 个元素，如下公式，在给定第 t 帧数据，有倒谱数据  $Δc(t,i)$ 如下公式所示：

$$
Δc(t,i) =c(t+iP+d)-c(t+iP-d)
$$

$$
SDC(t) = [Δc(t,0),Δc(t,1),\ldots,Δc(t,k-1)] 
$$

$$
0\le t \le N-1，0\le i \lt N-1
$$

SDC 扩展示例：

![图片](/assets/images/2020/ai/feature04.jpg)

SDC 特征更多的包含了时间上前后相关的信息，而且通过对 N， d， P， K参数的选择，可以使 SDC 表述特征的时长范围与一个音素的时长相比拟。因此在 SDC 特征所建立的 GMM 模型可以看成对各性别语音在音素级上底层特征的一种统计描述。在性别识别系统中， SDC 的 N， d， P， K 参数一般采用的（7，1， 3， 7），再加上 7 维 MFCC（C0—C6），一共 56 维特征。

实际上，在基于 GMM 模型的性别识别系统中， SDC 更多可以看成一种扩展算法，它用来对 MFCC 的一种扩展。其他声学特征也可以扩展为 SDC 特征，比如 PLP， LPCC 等。

##### 高斯化

性别识别所用参数，比如MFCC，本身都是随机矢量，因而具有相应的概率分布，训练和识别信道的不匹配也就体现在概率分布的差别上。受实际环境的影响，特征参数的概率分布往往发生改变。这时，一个很自然的想法就是对特征参数进行规整，使得训练和识别时候的特征参数的概率分布比较接近，这样两者之间不匹配的问题就应该能得到改善。

虽然特征参数的概率密度函数匹配应该是我们最直接的目标，但由于对它的估计既不方便也很难准确，所以我们一般还是通过概率密度函数的积分——累积分布函数(Cumulative Distribution Function, CDF)来表述概率分布匹配原理。

根据这个原理，特征参数变换函数可以由数据的累积分布函数获得，如下：
设特征参数变换函数为 x = T[y]，y 是规整前的特征参数， x 是规整变换后的特征参数。
再设 x 的累积分布函数为 $C_X(x)$ ，y 的累积分布函数是 $C_Y(y)$则特征参数变换函数应该使得：

$$
C_Y(y) = C_X(x) 
$$

由此可以得到：

$$
x=C_X^{-1}(C_Y(y))
$$

上述方法也被称为参数补偿，实际应用当中，为了简化算法实现过程，经常把训练和测试的数据概率分布都变到同一个事先给定的标准分布(通常是标准高斯分布 N (0,  I) )，这称作参数规整。
在实际的性别识别中，一般认为语音是短时平稳的，因此规整就采用 3 秒钟作为一次规整的单位，但是在实际中发现，采用 3 秒或者整段话 （2~5 分钟）规整基本上效果是一致的。这也就说明， 3 秒钟语音的分布与 5 分钟的语音的分布基本一致。

##### 倒谱域减均值

在倒谱域减去均值（Cepstral Mean Subtraction， CMS）是广泛应用于语音识别和性别识别中去除信道卷积噪声的一种算法。在完成语音到电信号的转化程中，也就相应的会将原始语音进行调制，这种调制反应在时域上是一种卷积，在倒谱域上是一种相加的关系。因此，在倒谱参数上减去均值，相应的也就去除了调制噪声。 CMS有一个前提假设是认为这个卷积噪声是一个线性时不变的过程，因此可以直接去除，实际的信道噪声远远不是一个线性、平稳的、时不变的过程，以电话通话举例，在不发声的时候，卷积噪声也很小，而说话声音很大的时候，卷积噪声也很小。但是，不管如何，减去均值以后总能去除一部分信道噪声。

另外，考虑到上述的分析过程，认为语音中的信道影响是一种非平稳的过程，一般的 CMS 处理都是在短时情况下对信号进行处理，在语音识别中典型的是采用一个 2 秒钟左右的窗函数进行 CMS。但是，在性别识别的运算中，发现窗函数对于 CMS 的作用不是很大，在 2 秒和 2 分钟的范围内对系统的识别率几乎没有任何影响，这是由于 NIST 数据库背景噪声比较干净，信道条件比较好，系统比较平稳的缘故

### GMM 模型的训练

这里涉及到EM算法，以及复杂的推导，具体可以详见我后面计划要写的博文

#### 模型的自适应

各个目标性别模型是在UBM的基础上利用该性别的数据进行适当地调整，也就是自适应的方法。一般而言，自适应的方法有多种多样，在语音数据相对较少的情况下，采用最大似然线性回归(Maximum likelihood linear regression,MLLR)，最大后验概率(Maximum a Posteriori， MAP)等方法，能够取得更好的性能。

但是对于性别识别来说，各性别数据足够多，这种情况下一般采用 MLE 估计。由于要训练到比较高的混合数(一般为 512)，以 UBM 为初始点的就显得很重要。这在前面讲 EM 算法的时候也说到了。各个性别模型参数估计和 UBM 是一样的。

#### 高斯后端分类器

后端采用高斯分类器，训练高斯分类器一般是在开发集数据上进行的，将所有的模型得分拼接成为一个得分向量，对于每个性别的数据进行训练。在训练单高斯后端模型时，首先进行LDA分析，将其线性变换为N-1 维的得分向量，这里N代表性别个数，然后在此得分向量上训练一个单高斯分类器。这种做法主要作用有两个：第一， 降维， 使得在较少的训练数据集上训练得到的模型较为可靠；第二，减少了得分之间的相关性。

### 实验
#### 数据说明
home_made 数据 8k

|集合\条| female | male|
|---|---|---|
|train|85182| 116530|
| test|437  | 563   |

#### 实验说明
以 GMM-UBM 系统为框架，模型混合数采用 256。特征采用 7 阶 MFCC 系数和 49 为SDC 拼起来得到 56 维特征，对每个性别训练一个模型，通过高斯后端归一化得分

#### 实验结果

|阈值\准确率（%）| female | male| fusion|
|---|---|---|---|
| 0.40|  96.796（423）| 93.961（529） | 95.2% |
| 0.45|  95.652（418）| 94.849（534） | 96.1% |
| 0.50|  94.050（411）| 96.269（542） | 95.3% |
| 0.55|  92.906（406）| 96.447（543） | 94.9% |
| 0.60|  92.219（403）| 96.802（545） | 94.8% |

## 3. DNN-Embedding 性别识别系统框架
### 背景

上述GMM框架使用的是单帧短时频谱特征Mel频谱倒谱特征(Mel-frequency cepstral coefficient，MFCC)。 这里存在以下问题：短时特征默认假设服从混合高斯分布； 短时特征包含的信息有限，无法准确有效捕捉性别这种在较长时间中才有所体现的信息，并且在计算后验概率时使用的是拼接了多帧的声学特征，在时间尺度上所包含的信息与单帧短时频谱特征不一致； 另外，短时频谱特征是通过人工设计的基本的信号处理方法得到的，没有利用到数据中的信息，并且特征中同时包含有信道、语种和说话人身份等多种信息，这些信息可能会对性别识别任务造成一定程度的干扰。 

### DNN-Embedding 框架

近几年来，DNN广泛应用于人脸识别、 说话人识别这种类别数目通常不固定的开集识别任务上，并取得了很好的效果。DNN具有强大分类能力的本质原因在于它从数据中学习到了更有利于特定分类任务的特征表示。 因此DNN也常用来作为特征提取工具，所以我们设计了类似DNN的Bottleneck特征框架代替GMM模型来实现性别识别，整体流程如下图：

![图片](/assets/images/2020/ai/dnn01.jpg)

其中DNN-Embedding部分部分，结构如下图所示：

![图片](/assets/images/2020/ai/tdnn01.jpg)

整体分成2个部分，frame-level 与 segment-level，特征提取后，多帧数据经过神经网络，在Pooling层累积，收集长时信息，形成片段，然后再进过Embedding层，最终输出，根据CE准则计算Loss，然后反向更新网络，这样不断循环，直至收敛。输出2个节点，代表不同的性别结果。

其中神经网络采用的是TDNN，通过配置不同的context，可以使得output-node学习到更长的上下文信息，从而判断的更为准确，具体详细结构如下图：

![图片](/assets/images/2020/ai/tdnn02.jpg)

### 实验 1
#### 数据说明
home_made  8k 标注数据

|集合\条| female | male|
|---|---|---|
|train|85182| 116530|
| test|437  | 563   |

#### 实验说明

以 TDNN 系统为框架，7层TDNN，每层节点数512，ReLU激活，CE准则，输出维度为2，输入特征为40维，通过比较log-softmax输出得分，判定性别

#### 实验结果

|-| female | male| confusion|
|---|---|---|---|
| 准确率（%）|  80.549（352）| 98.401（554） | 90.6% |

### 实验 2 
#### 数据说明

|集合\条| female | male|
|---|---|---|
|train_1 |85182| 116530|
|aishell |59591| 47467|
|librispeech |141480| 150887|
|ted |223| 553|
| test|437  | 563   |

### 实验结果

|-| female | male| confusion|
|---|---|---|---|
| 准确率（%）|  98.80| 96.79 | 97.76 |

## 4. 结论

- 从结果上来看，训练数据较少时，GMM 效果优于 DNN，当达到一定规模时，DNN的效果超越了GMM
- 说明了DNN强大的自我学习鉴别能力，只要提供足够多的数据供它学习